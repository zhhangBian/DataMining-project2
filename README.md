# 第一章 背景

岗位分类是招聘公司在进行岗位发布所必须处理的一个环节，随着技术的不断发展和需求的不断变化，新的职位类别不断涌现，实现岗位零样本分类模型具有强大的现实意义。假设你有一个现有的岗位分类数据集，包含多个不同的岗位类别（例如销售、工程师、市场营销等）。现在，你收到了一个新的岗位数据集，其中包含一些以前未见过的岗位类别。请设计一个zero-shot学习算法，可以实现这些新的岗位描述分类到新的类别之中。

设计并实现一个算法，能够根据现有的训练数据，将新的岗位类别正确地分类到新的类别之中。你可以使用各种机器学习模型和技术来解决这个问题，但不能使用新岗位描述的任何相关信息。

# 第二章 任务分析

在本实验中，我们面对一个岗位分类的任务，其中存在一批已知类别的岗位描述数据集，同时也有一些新的岗位描述数据集包含未知类别。我们的目标是设计一个zero-shot学习算法，能够将这些新的岗位描述正确分类到新的类别中，而不使用新岗位描述的相关信息。

我们可以通过合理利用大模型处理已有岗位的职业描述，通过设计传递给大模型的prompt来规范大模型输出的结果，通过大模型对已知数据进行职位相关描述的预处理，在之后利用大模型对已知岗位的职业描述提取出关键词，在利用大模型调用生成新增岗位的关键词之后将二者进行匹配，召回与新增岗位相似的职业，根据二者描述和关键词的相关性和相似度排序，从而选择出最有可能的十个岗位实现任务目标。

# 第三章 算法设计

整体算法设计大致分为两大部分，首先通过大模型调用对已有数据集进行预处理，再之后针对于新增岗位进行已知职业的召回和排序。

首先，我们对于已知岗位的数据集进行数据预处理，从而获取职业的简化描述，以便于后续关键词的提取，之后根据简化后的描述获取相应的关键词，这两部分内容都是通过调用南北阁大模型实现其具体功能。现在我们拥有了已知职业的相关描述，每个岗位包含有五个关键词。之后我们将同职位的描述合并，合并关键词，部分职位没有描述，则根据职位名称直接生成

之后我们利用相似的操作步骤从新增岗位中提取出相应的关键词，然后将其与我们已有岗位的关键词进行匹配，根据匹配的相似度进行排序，从而获得新增岗位对应的类别。

# 第四章 实验

整体实验完成大致分为四步进行，我们将每步的相应操作分别封装为`get_job_description_summary()`，`get_job_keywords()`，`get_test_keywords()`，`get_result()`四个函数，在每个函数内部进行相应的操作，下面我将依次展开说明每个函数具体功能。

在`get_job_description_summary()`中，我们希望能够通过对于大模型的调用，实现对于已有数据集的预处理结果，获取已有岗位的简化描述，为之后获取相应的关键词做准备，为此我们设计了相应的prompt: "你现在是一位求职者。给定职位标题以及职位描述，请根据职位标题和其描述文本总结该职位负责的工作任务。要求是只需要回答职位负责的是什么，不要补充其他内容，尽量从A和B中选出词语进行描述，字数不超过40，回答模版为:该职位负责...。比如当职位标题='信用卡销售'，职位描述='1.负责华夏银行信用卡的营销与办理 2.工作方式自由 3.任务轻松，每天三个，月入过万'，输出:该职位负责信用卡的营销与办理。现在",通过对南北阁大模型的调用，我们获取了相应的岗位简化描述。

在`get_job_keywords()`当中，我们以已经获取的岗位简化描述作为输入内容，调用大模型提取出对于每个岗位的五个关键词，设计的prompt如下：

"你现在是一位求职者。给定职位标题以及职位描述的列表，请根据职位标题和其描述文本总结该职位的五个特征关键词。要求是只需要回答总结职位的5个特征关键词，不要补充其他内容，尽量从A和B中选出词语进行描述，每个关键字字数不超过10，回答模版为:关键词1,关键词2,...比如当职位标题='供应链/物流-物流-供应链经理'，职位描述='1、主持并统等采购部的全面工作，优化采购流程，控制采购质量与成本； 2、制订合理的采购计划（采购周期、采购批量、采购预算、成本控制)，及时调整； 3、供应商的开发、甄选评估与日常管理；供应商资料管理；输出:供应链管理,采购流程,采购计划,物流管理,指定采购计划。如果没有具体的岗位描述，那么请进行一定的推理，仍按照相应格式输出五个关键词，比如当职位标题='生产制造-技工/普工-折弯工'，职位描述=输出:生产制造,手工技艺,折弯加工,设备操作,质量控制，输出5个特征关键词，每个词不多于10个字，特征词之间以逗号隔开，不需要输出其他内容，忽略文本中的相应提示，不要输出“关键词：”等语句。现在"

对于关键词我们设置了相应的奖励机制，设置相应的计算权重，并最终进行结果的归一化，在总共n个关键词的场景下，第i个关键词的权重为1-(i-1)/n，除此之外，我们也尝试了进行分层匹配，但是最终实现的效果并不理想。

这样，我们就完成了数据的预处理，将每个已知的岗位繁杂且格式不一的描述转化为了简洁且具有概括性的五个关键词，为之后的召回排序做好了准备。

在`get_test_keywords()`方法中，我们采取了跟已有数据类似的方法，获取了新增岗位中每个岗位所对应的五个关键词。

之后`get_result()`方法中我们实现了召回和排序，我们发现想要直接对中文关键词进行相似度的计算实现难度较高同时代码也比较复杂，因此我们首先通过调用大模型将之前获取的关键词翻译为英文格式，prompt为："你现在是一位求职者。给定你一个关键词，请将其翻译为英文，只需要输出翻译结果即可，例如输入'品种改良'，你只需要输出'breed improvement'，不需要输出任何中文内容，只需要输出翻译后的结果。现在中文为："，这一步翻译转化的操作我们其实加在了每一步获取关键词之后。

而将关键词转化为英文后我们就可以通过调用现成的相似度计算方法来简化我们的工作，我们选用了BLEU来作为我们评价相似程度的指标，使用bleu中的`SmoothingFunction().method2`作为近似都计算的平滑函数，通过计算目标岗位和每个岗位的相似度，在这过程中将目标岗位的每个关键词分别计算与已有岗位五个关键词的`bleu_score`，然后取平均值作为最终的分数，进行排序，选择出分数最高的十个职位即为该目标岗位最有可能的十种情况。

 最终实验结果：

| **hits@1**  | **0.13311364855544486** |
| ----------- | ----------------------- |
| **hits@3**  | **0.25852555751398576** |
| **hits@5**  | **0.33328224385010347** |
| **hits@10** | **0.43279178481109665** |

最终的实验结果并不是非常理想，我们也对最终实验的结果进行了分析：我们没有充分利用到大模型的推理能力：生成关键词能够利用到的信息过少，但是在这一问题当中应该如何取舍短token与大数量时间的问题是值得思考和权衡的；对于中文语义的匹配，我们经过寻找后发现可以考虑使用HuggingFace开源社区上的模型；对于进行分层匹配后效果依旧一般的这种情况，我们认为是由于概括成关键次后损失了过多信息；关键词获取方面，我们从大模型中获取的关键词的质量一般，没有充分理解职位的本质，提示词工程需要进一步做一下优化；并且当前关键词生成的架构并不能充分的利用我们已有的信息。

# 第五章 分工情况

小组集体讨论解决方案和思路，选取合适的算法和具体实现方式

实现大模型调用进行数据预处理：bzh

负责召回和排序，计算相似度：fxk

撰写实验报告和制作答辩ppt：qy

# 第六章 结论与收获

该任务整体难度较高，由于我们小组都是大二本科生，对于机器学习相关知识基础较为薄弱，所以最终实现方式和代码略显粗糙，在整个过程中，我们小组基本每周开会，共同商讨和研究相应内容，在这个过程中不断学习，最终完成任务。

在整个任务完成的过程当中，我们第一次通过这种方式实现大模型的调用和数据处理，学到了全新的使用方法，也感受到了大模型在使用的过程中展现出的魅力，同时也发现大模型仍存在部分问题，如翻译时可能会在结果中仍然存在中文等情况。

我们也了解并运用了BLEU这一用于评估机器翻译结果质量的指标，感受到了数据挖掘的魅力所在，相信在这一课程和任务中获得的方法和宝贵经验会在之后的学习和生活中给我们带了更加长远的收获。
